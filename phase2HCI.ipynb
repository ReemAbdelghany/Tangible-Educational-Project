{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2916b42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dlib in c:\\users\\hp\\anaconda3\\lib\\site-packages (19.24.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b195149d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepface in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.0.81)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from deepface) (1.22.4)\n",
      "Requirement already satisfied: gdown>=3.10.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from deepface) (4.7.3)\n",
      "Requirement already satisfied: pandas>=0.23.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from deepface) (1.3.4)\n",
      "Requirement already satisfied: opencv-python>=4.5.5.64 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from deepface) (4.7.0.72)\n",
      "Requirement already satisfied: tensorflow>=1.9.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from deepface) (2.12.0)\n",
      "Requirement already satisfied: keras>=2.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from deepface) (2.12.0)\n",
      "Requirement already satisfied: Pillow>=5.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from deepface) (10.1.0)\n",
      "Requirement already satisfied: tqdm>=4.30.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from deepface) (4.62.3)\n",
      "Requirement already satisfied: fire>=0.4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from deepface) (0.5.0)\n",
      "Requirement already satisfied: mtcnn>=0.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from deepface) (0.1.1)\n",
      "Requirement already satisfied: Flask>=1.1.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from deepface) (1.1.2)\n",
      "Requirement already satisfied: gunicorn>=20.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from deepface) (21.2.0)\n",
      "Requirement already satisfied: retina-face>=0.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from deepface) (0.0.13)\n",
      "Requirement already satisfied: Deprecated>=1.2.13 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from deepface) (1.2.14)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from Deprecated>=1.2.13->deepface) (1.12.1)\n",
      "Requirement already satisfied: six in c:\\users\\hp\\anaconda3\\lib\\site-packages (from fire>=0.4.0->deepface) (1.16.0)\n",
      "Requirement already satisfied: termcolor in c:\\users\\hp\\anaconda3\\lib\\site-packages (from fire>=0.4.0->deepface) (2.3.0)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from Flask>=1.1.2->deepface) (2.0.2)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from Flask>=1.1.2->deepface) (2.11.3)\n",
      "Requirement already satisfied: click>=5.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from Flask>=1.1.2->deepface) (8.0.3)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from Flask>=1.1.2->deepface) (2.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from click>=5.1->Flask>=1.1.2->deepface) (0.4.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gdown>=3.10.1->deepface) (3.3.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gdown>=3.10.1->deepface) (4.10.0)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gdown>=3.10.1->deepface) (2.26.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gunicorn>=20.1.0->deepface) (21.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from Jinja2>=2.10.1->Flask>=1.1.2->deepface) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas>=0.23.4->deepface) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas>=0.23.4->deepface) (2021.3)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow>=1.9.0->deepface) (2.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=1.9.0->deepface) (58.0.4)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=1.9.0->deepface) (16.0.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=1.9.0->deepface) (23.3.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=1.9.0->deepface) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=1.9.0->deepface) (0.31.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=1.9.0->deepface) (2.12.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=1.9.0->deepface) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=1.9.0->deepface) (4.8.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=1.9.0->deepface) (0.4.8)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=1.9.0->deepface) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=1.9.0->deepface) (1.54.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=1.9.0->deepface) (3.20.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=1.9.0->deepface) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=1.9.0->deepface) (1.4.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=1.9.0->deepface) (2.12.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=1.9.0->deepface) (3.2.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow>=1.9.0->deepface) (0.37.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.0.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow>=1.9.0->deepface) (0.1.0)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow>=1.9.0->deepface) (1.7.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow>=1.9.0->deepface) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow>=1.9.0->deepface) (2.17.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow>=1.9.0->deepface) (0.7.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow>=1.9.0->deepface) (3.4.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow>=1.9.0->deepface) (0.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow>=1.9.0->deepface) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow>=1.9.0->deepface) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow>=1.9.0->deepface) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow>=1.9.0->deepface) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow>=1.9.0->deepface) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow>=1.9.0->deepface) (0.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests[socks]->gdown>=3.10.1->deepface) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests[socks]->gdown>=3.10.1->deepface) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests[socks]->gdown>=3.10.1->deepface) (2023.7.22)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow>=1.9.0->deepface) (3.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from packaging->gunicorn>=20.1.0->deepface) (2.4.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cefed24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting face_recognition\n",
      "  Using cached face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from face_recognition) (8.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from face_recognition) (1.22.4)\n",
      "Collecting face-recognition-models>=0.3.0\n",
      "  Using cached face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
      "Requirement already satisfied: dlib>=19.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from face_recognition) (19.24.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\hp\\anaconda3\\lib\\site-packages (from face_recognition) (10.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from Click>=6.0->face_recognition) (0.4.4)\n",
      "Building wheels for collected packages: face-recognition-models\n",
      "  Building wheel for face-recognition-models (setup.py): started\n",
      "  Building wheel for face-recognition-models (setup.py): finished with status 'done'\n",
      "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566185 sha256=0c420b360fc88455af4228233f16ad8d3e6b419a1b387b6ee77fc67205ad7fa7\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\22\\a8\\60\\4a2aeb763d63f50190f4c4e07069a22245347eeafdb3a67551\n",
      "Successfully built face-recognition-models\n",
      "Installing collected packages: face-recognition-models, face-recognition\n",
      "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "edd1baae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-contrib-python==4.6.0.66 in c:\\users\\hp\\anaconda3\\lib\\site-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from opencv-contrib-python==4.6.0.66) (1.22.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-contrib-python==4.6.0.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc24d292",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymongo\n",
      "  Downloading pymongo-4.6.1-cp39-cp39-win_amd64.whl (472 kB)\n",
      "Collecting dnspython<3.0.0,>=1.16.0\n",
      "  Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
      "Installing collected packages: dnspython, pymongo\n",
      "Successfully installed dnspython-2.4.2 pymongo-4.6.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymongo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e44cee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imutils\n",
      "  Downloading imutils-0.5.4.tar.gz (17 kB)\n",
      "Building wheels for collected packages: imutils\n",
      "  Building wheel for imutils (setup.py): started\n",
      "  Building wheel for imutils (setup.py): finished with status 'done'\n",
      "  Created wheel for imutils: filename=imutils-0.5.4-py3-none-any.whl size=25860 sha256=721dbb2cef6c5e05258dad1177a7811533480758f09cfec962de419ae4e66b8e\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\4b\\a5\\2d\\4a070a801d3a3d93f033d3ee9728f470f514826e89952df3ea\n",
      "Successfully built imutils\n",
      "Installing collected packages: imutils\n",
      "Successfully installed imutils-0.5.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35517998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.4.3)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (1.22.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\users\\hp\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16eb7fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cv2 as cv\n",
    "import os\n",
    "import numpy as np\n",
    "import dlib\n",
    "import face_recognition\n",
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "import threading\n",
    "from deepface import DeepFace\n",
    "from threading import Thread\n",
    "import pymongo\n",
    "import cv2.aruco as aruco\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74999e34-81b2-49d9-aefd-fde376fdb43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Replace your connection string with the actual one\n",
    "connection_string = \"mongodb+srv://reemabdelghany:reemabdelghany@cluster4.mwakgnd.mongodb.net/?retryWrites=true&w=majority\"\n",
    "\n",
    "# Create a MongoClient\n",
    "client = MongoClient(connection_string)\n",
    "\n",
    "# Access your database (replace 'your_database' with your actual database name)\n",
    "db = client.HCI\n",
    "\n",
    "# Access your collection (replace 'game_data' with your desired collection name)\n",
    "collection = db.phase2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e914fc8a-9436-4555-985c-fccd0ee35690",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to the extracted shape predictor file\n",
    "shape_predictor_path = r\"E:\\Uni\\y3\\hci\\phase2\\shape_predictor_68_face_landmarks.dat\"\n",
    "\n",
    "# Load the pre-trained face detector from dlib\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "shape_predictor = dlib.shape_predictor(shape_predictor_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e3d115b-85da-4510-9c41-b214cdfa2a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable to store the current user's game level\n",
    "current_user_game_level = None\n",
    "# Create a dictionary to store emotions and their counts\n",
    "emotion_counts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7190f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Replace your connection string with the actual one\n",
    "connection_string = \"mongodb+srv://reemabdelghany:reemabdelghany@cluster4.mwakgnd.mongodb.net/?retryWrites=true&w=majority\"\n",
    "\n",
    "# Create a MongoClient\n",
    "client = MongoClient(connection_string)\n",
    "\n",
    "# Access your database (replace 'your_database' with your actual database name)\n",
    "db = client.HCI\n",
    "\n",
    "# Access your collection (replace 'game_data' with your desired collection name)\n",
    "collection = db.phase2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5d1361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_path = r\"E:\\Uni\\y3\\hci\\phase2\\shape_predictor_68_face_landmarks.dat\"\n",
    "predictor = dlib.shape_predictor(predictor_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15d7f34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eyegaze_data_list = []  # List to accumulate eyegaze data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9773d81b",
   "metadata": {},
   "source": [
    "# FINAL CODE VERSION RIGHT NOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c579765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion: surprise\n",
      "Emotion: fear\n",
      "Emotion: fear\n",
      "Emotion: fear\n",
      "Emotion: fear\n",
      "Emotion: surprise\n",
      "Emotion: angry\n",
      "Emotion: neutral\n",
      "Emotion: neutral\n",
      "Emotion: happy\n",
      "Emotion: neutral\n",
      "Emotion: neutral\n",
      "Emotion: happy\n",
      "Emotion: sad\n",
      "Emotion: sad\n",
      "Emotion: neutral\n",
      "Emotion: neutral\n",
      "Emotion: neutral\n",
      "Emotion: sad\n",
      "Emotion: happy\n",
      "Emotion: sad\n",
      "Emotion: angry\n",
      "Emotion: happy\n",
      "Emotion: happy\n",
      "Emotion: happy\n",
      "Emotion: happy\n",
      "Emotion: neutral\n",
      "Emotion: happy\n",
      "Emotion: neutral\n",
      "Emotion: happy\n",
      "Emotion: neutral\n",
      "Emotion: happy\n",
      "Emotion: happy\n",
      "Emotion: happy\n",
      "Emotion: neutral\n",
      "Emotion: happy\n",
      "Emotion: neutral\n",
      "Emotion: fear\n",
      "Emotion: neutral\n",
      "Updated emotion and eyegaze_data for yousef: happy (24%), Eyegaze Data: [{'left_eye_center': [224, 255], 'right_eye_center': [287, 247], 'left_pupil': (237, 256), 'right_pupil': (275, 251)}, {'left_eye_center': [211, 250], 'right_eye_center': [282, 245], 'left_pupil': (226, 252), 'right_pupil': (268, 249)}, {'left_eye_center': [198, 236], 'right_eye_center': [274, 234], 'left_pupil': (213, 238), 'right_pupil': (260, 237)}, {'left_eye_center': [213, 231], 'right_eye_center': [276, 230], 'left_pupil': (226, 233), 'right_pupil': (263, 232)}, {'left_eye_center': [225, 234], 'right_eye_center': [302, 234], 'left_pupil': (242, 237), 'right_pupil': (287, 237)}, {'left_eye_center': [230, 234], 'right_eye_center': [303, 236], 'left_pupil': (245, 237), 'right_pupil': (289, 238)}, {'left_eye_center': [270, 253], 'right_eye_center': [329, 255], 'left_pupil': (283, 256), 'right_pupil': (317, 257)}, {'left_eye_center': [252, 314], 'right_eye_center': [302, 315], 'left_pupil': (263, 316), 'right_pupil': (292, 317)}, {'left_eye_center': [241, 303], 'right_eye_center': [293, 301], 'left_pupil': (252, 304), 'right_pupil': (282, 303)}, {'left_eye_center': [191, 342], 'right_eye_center': [239, 329], 'left_pupil': (201, 340), 'right_pupil': (230, 332)}, {'left_eye_center': [199, 330], 'right_eye_center': [247, 321], 'left_pupil': (209, 329), 'right_pupil': (238, 324)}, {'left_eye_center': [236, 319], 'right_eye_center': [285, 319], 'left_pupil': (247, 321), 'right_pupil': (275, 321)}, {'left_eye_center': [237, 322], 'right_eye_center': [288, 321], 'left_pupil': (248, 323), 'right_pupil': (278, 323)}, {'left_eye_center': [232, 342], 'right_eye_center': [276, 338], 'left_pupil': (242, 343), 'right_pupil': (267, 341)}, {'left_eye_center': [227, 333], 'right_eye_center': [276, 329], 'left_pupil': (238, 333), 'right_pupil': (266, 331)}, {'left_eye_center': [222, 223], 'right_eye_center': [293, 222], 'left_pupil': (237, 225), 'right_pupil': (278, 224)}, {'left_eye_center': [206, 222], 'right_eye_center': [278, 219], 'left_pupil': (222, 223), 'right_pupil': (263, 221)}, {'left_eye_center': [242, 270], 'right_eye_center': [318, 269], 'left_pupil': (258, 272), 'right_pupil': (302, 272)}, {'left_eye_center': [247, 273], 'right_eye_center': [322, 272], 'left_pupil': (263, 276), 'right_pupil': (307, 275)}, {'left_eye_center': [239, 258], 'right_eye_center': [316, 257], 'left_pupil': (254, 260), 'right_pupil': (302, 259)}, {'left_eye_center': [244, 238], 'right_eye_center': [320, 236], 'left_pupil': (260, 239), 'right_pupil': (306, 238)}, {'left_eye_center': [242, 240], 'right_eye_center': [318, 239], 'left_pupil': (257, 241), 'right_pupil': (304, 240)}, {'left_eye_center': [239, 240], 'right_eye_center': [314, 237], 'left_pupil': (254, 241), 'right_pupil': (300, 239)}, {'left_eye_center': [236, 241], 'right_eye_center': [313, 236], 'left_pupil': (252, 241), 'right_pupil': (299, 238)}, {'left_eye_center': [230, 231], 'right_eye_center': [310, 228], 'left_pupil': (247, 232), 'right_pupil': (295, 230)}, {'left_eye_center': [226, 201], 'right_eye_center': [315, 195], 'left_pupil': (245, 202), 'right_pupil': (298, 198)}, {'left_eye_center': [236, 258], 'right_eye_center': [301, 254], 'left_pupil': (250, 259), 'right_pupil': (288, 256)}, {'left_eye_center': [228, 265], 'right_eye_center': [296, 258], 'left_pupil': (243, 266), 'right_pupil': (282, 261)}, {'left_eye_center': [221, 271], 'right_eye_center': [291, 260], 'left_pupil': (235, 269), 'right_pupil': (277, 263)}, {'left_eye_center': [230, 280], 'right_eye_center': [298, 271], 'left_pupil': (245, 281), 'right_pupil': (284, 275)}, {'left_eye_center': [276, 263], 'right_eye_center': [341, 266], 'left_pupil': (290, 266), 'right_pupil': (327, 268)}, {'left_eye_center': [184, 295], 'right_eye_center': [237, 290], 'left_pupil': (195, 295), 'right_pupil': (227, 292)}, {'left_eye_center': [188, 278], 'right_eye_center': [248, 280], 'left_pupil': (200, 280), 'right_pupil': (238, 281)}, {'left_eye_center': [199, 247], 'right_eye_center': [275, 243], 'left_pupil': (215, 248), 'right_pupil': (260, 245)}, {'left_eye_center': [197, 245], 'right_eye_center': [274, 242], 'left_pupil': (214, 247), 'right_pupil': (259, 245)}, {'left_eye_center': [197, 247], 'right_eye_center': [274, 243], 'left_pupil': (213, 248), 'right_pupil': (259, 246)}, {'left_eye_center': [193, 251], 'right_eye_center': [265, 239], 'left_pupil': (209, 251), 'right_pupil': (251, 244)}, {'left_eye_center': [185, 261], 'right_eye_center': [258, 247], 'left_pupil': (200, 261), 'right_pupil': (244, 252)}, {'left_eye_center': [183, 265], 'right_eye_center': [256, 250], 'left_pupil': (198, 264), 'right_pupil': (242, 255)}, {'left_eye_center': [201, 280], 'right_eye_center': [278, 274], 'left_pupil': (216, 282), 'right_pupil': (265, 279)}, {'left_eye_center': [199, 283], 'right_eye_center': [275, 276], 'left_pupil': (215, 285), 'right_pupil': (261, 281)}, {'left_eye_center': [206, 284], 'right_eye_center': [282, 278], 'left_pupil': (221, 286), 'right_pupil': (268, 282)}, {'left_eye_center': [220, 280], 'right_eye_center': [292, 276], 'left_pupil': (235, 282), 'right_pupil': (278, 280)}, {'left_eye_center': [214, 284], 'right_eye_center': [287, 278], 'left_pupil': (229, 285), 'right_pupil': (274, 282)}, {'left_eye_center': [206, 288], 'right_eye_center': [282, 282], 'left_pupil': (221, 289), 'right_pupil': (268, 286)}, {'left_eye_center': [207, 290], 'right_eye_center': [284, 287], 'left_pupil': (222, 293), 'right_pupil': (271, 291)}, {'left_eye_center': [207, 291], 'right_eye_center': [285, 288], 'left_pupil': (221, 294), 'right_pupil': (271, 292)}, {'left_eye_center': [205, 291], 'right_eye_center': [281, 287], 'left_pupil': (220, 293), 'right_pupil': (267, 291)}, {'left_eye_center': [217, 292], 'right_eye_center': [291, 292], 'left_pupil': (232, 295), 'right_pupil': (277, 295)}, {'left_eye_center': [200, 297], 'right_eye_center': [279, 293], 'left_pupil': (215, 300), 'right_pupil': (265, 298)}, {'left_eye_center': [189, 299], 'right_eye_center': [269, 294], 'left_pupil': (204, 301), 'right_pupil': (254, 298)}, {'left_eye_center': [189, 298], 'right_eye_center': [268, 292], 'left_pupil': (205, 301), 'right_pupil': (253, 298)}, {'left_eye_center': [184, 299], 'right_eye_center': [264, 294], 'left_pupil': (200, 302), 'right_pupil': (249, 299)}, {'left_eye_center': [179, 297], 'right_eye_center': [263, 291], 'left_pupil': (194, 298), 'right_pupil': (249, 295)}, {'left_eye_center': [176, 288], 'right_eye_center': [265, 281], 'left_pupil': (192, 289), 'right_pupil': (250, 284)}, {'left_eye_center': [176, 295], 'right_eye_center': [261, 289], 'left_pupil': (191, 295), 'right_pupil': (247, 292)}, {'left_eye_center': [179, 298], 'right_eye_center': [260, 289], 'left_pupil': (194, 299), 'right_pupil': (246, 294)}, {'left_eye_center': [183, 301], 'right_eye_center': [264, 294], 'left_pupil': (199, 303), 'right_pupil': (249, 298)}, {'left_eye_center': [184, 302], 'right_eye_center': [264, 296], 'left_pupil': (198, 304), 'right_pupil': (250, 300)}, {'left_eye_center': [207, 264], 'right_eye_center': [279, 270], 'left_pupil': (222, 266), 'right_pupil': (266, 270)}, {'left_eye_center': [201, 272], 'right_eye_center': [277, 273], 'left_pupil': (217, 276), 'right_pupil': (264, 276)}, {'left_eye_center': [195, 266], 'right_eye_center': [266, 264], 'left_pupil': (210, 267), 'right_pupil': (253, 266)}, {'left_eye_center': [200, 257], 'right_eye_center': [271, 255], 'left_pupil': (215, 259), 'right_pupil': (257, 258)}, {'left_eye_center': [232, 270], 'right_eye_center': [287, 271], 'left_pupil': (244, 273), 'right_pupil': (277, 274)}, {'left_eye_center': [228, 303], 'right_eye_center': [307, 305], 'left_pupil': (244, 306), 'right_pupil': (293, 307)}, {'left_eye_center': [224, 283], 'right_eye_center': [295, 273], 'left_pupil': (239, 283), 'right_pupil': (282, 277)}, {'left_eye_center': [223, 279], 'right_eye_center': [296, 274], 'left_pupil': (237, 280), 'right_pupil': (284, 277)}]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bson import json_util\n",
    "# Function to recognize emotion and facial identification\n",
    "total_emotions = 0\n",
    "# Function to recognize emotion and facial identification\n",
    "def recognize_faces_emotions(img, name):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces using dlib\n",
    "    faces = face_detector(gray)\n",
    "\n",
    "    for face in faces:\n",
    "        # Predict facial landmarks\n",
    "        landmarks = shape_predictor(gray, face)\n",
    "\n",
    "        # Extract the region of interest (ROI)\n",
    "        x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "        roi = img[y:y + h, x:x + w]\n",
    "\n",
    "        try:\n",
    "            # Perform emotion analysis using deepface\n",
    "            emotions = DeepFace.analyze(roi, actions=['emotion'], enforce_detection=False)\n",
    "\n",
    "            # Extract the dominant emotion for the first face in the list\n",
    "            dominant_emotion = emotions[0]['dominant_emotion']\n",
    "\n",
    "            # Print the results\n",
    "            print(f\"Emotion: {dominant_emotion}\")\n",
    "\n",
    "            # Draw a rectangle around the face and display the name and emotion\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            text = f\"Person: {name}, Emotion: {dominant_emotion}\"\n",
    "            cv2.putText(img, text, (x + 6, y + h - 6), font, 0.5, (255, 255, 255), 1)\n",
    "        except ValueError as e:\n",
    "            # Handle the case where a face is not detected in the region of interest\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "# Path to the folder containing images\n",
    "folder_path = r\"E:\\Uni\\y3\\hci\\phase2\\faces\"\n",
    "\n",
    "# Create a list to store known face encodings and corresponding names\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "\n",
    "# Load images and create face encodings for each person in the folder\n",
    "for person_folder in os.listdir(folder_path):\n",
    "    person_folder_path = os.path.join(folder_path, person_folder)\n",
    "\n",
    "    if os.path.isdir(person_folder_path):\n",
    "        for image_file in os.listdir(person_folder_path):\n",
    "            image_path = os.path.join(person_folder_path, image_file)\n",
    "\n",
    "            # Load the image and create face encodings\n",
    "            image = face_recognition.load_image_file(image_path)\n",
    "            encoding = face_recognition.face_encodings(image)[0]\n",
    "\n",
    "            # Append the encoding and corresponding name to the lists\n",
    "            known_face_encodings.append(encoding)\n",
    "            known_face_names.append(person_folder)\n",
    "            \n",
    "\n",
    "def create_heatmap(eyegaze_data):\n",
    "    x = [point[\"left_eye_center\"][0] for point in eyegaze_data] + [point[\"right_eye_center\"][0] for point in eyegaze_data]\n",
    "    y = [point[\"left_eye_center\"][1] for point in eyegaze_data] + [point[\"right_eye_center\"][1] for point in eyegaze_data]\n",
    "\n",
    "    plt.hist2d(x, y, bins=(100, 100), cmap=plt.cm.jet)\n",
    "    plt.colorbar()\n",
    "    plt.title('Eyegaze Heatmap')\n",
    "    plt.xlabel('X-coordinate')\n",
    "    plt.ylabel('Y-coordinate')\n",
    "    plt.show()\n",
    "\n",
    "# Declare the 'name' variable before the loop\n",
    "name = \"Unknown\"\n",
    "\n",
    "# Start capturing video from camera index 0 for emotion detection and facial recognition\n",
    "cap_emotion = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "\n",
    "def convert_to_lists(data):\n",
    "    if isinstance(data, np.ndarray):\n",
    "        return data.tolist()\n",
    "    elif isinstance(data, list):\n",
    "        return [convert_to_lists(item) for item in data]\n",
    "    elif isinstance(data, np.int32):\n",
    "        return int(data)  # Convert int32 to regular Python integer\n",
    "    elif isinstance(data, dict):\n",
    "        return {key: convert_to_lists(value) for key, value in data.items()}\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "# Function to process frames in a separate thread\n",
    "def process_frames():\n",
    "    global name, cap_emotion\n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap_emotion.read()\n",
    "\n",
    "        # Process every 5th frame (adjust as needed)\n",
    "        if frame_count % 10 == 0:\n",
    "            # Find face locations and encodings in the current frame\n",
    "            face_locations = face_recognition.face_locations(frame)\n",
    "            face_encodings = face_recognition.face_encodings(frame, face_locations)\n",
    "            # Convert the BGR image to grayscale\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            # Detect faces in the grayscale image\n",
    "            detector = dlib.get_frontal_face_detector()\n",
    "            faces = detector(gray)\n",
    "            for face in faces:\n",
    "                # Get facial landmarks\n",
    "                landmarks = predictor(gray, face)\n",
    "                # Extract coordinates of both eyes\n",
    "                left_eye_pts = [(landmarks.part(i).x, landmarks.part(i).y) for i in range(36, 42)]\n",
    "                right_eye_pts = [(landmarks.part(i).x, landmarks.part(i).y) for i in range(42, 48)]\n",
    "                # Calculate the centroid (average) of the eye landmarks\n",
    "                left_eye_center = np.mean(left_eye_pts, axis=0, dtype=np.int32)\n",
    "                right_eye_center = np.mean(right_eye_pts, axis=0, dtype=np.int32)\n",
    "                # Extract pupil coordinates\n",
    "                left_pupil = landmarks.part(39).x, landmarks.part(39).y  # Left pupil is at index 39\n",
    "                right_pupil = landmarks.part(42).x, landmarks.part(42).y  # Right pupil is at index 42\n",
    "                # Update the 'eyegaze_data' field in the database\n",
    "                eyegaze_data_list.append({\n",
    "                    \"left_eye_center\": convert_to_lists(left_eye_center),\n",
    "                    \"right_eye_center\": convert_to_lists(right_eye_center),\n",
    "                    \"left_pupil\": convert_to_lists(left_pupil),\n",
    "                    \"right_pupil\": convert_to_lists(right_pupil)\n",
    "                })\n",
    "                # Draw circles representing the eye centers\n",
    "                cv2.circle(frame, tuple(left_eye_center), 3, (0, 0, 255), -1)\n",
    "                cv2.circle(frame, tuple(right_eye_center), 3, (0, 0, 255), -1)\n",
    "                # Draw lines representing the axes for the left eye\n",
    "                cv2.line(frame, tuple(left_eye_center), left_pupil, (0, 255, 0), 2)\n",
    "\n",
    "                # Draw lines representing the axes for the right eye\n",
    "                cv2.line(frame, tuple(right_eye_center), right_pupil, (0, 255, 0), 2)\n",
    "\n",
    "                # Display the coordinates of the pupils\n",
    "                cv2.putText(frame, f\"Left Pupil - X: {left_pupil[0]}, Y: {left_pupil[1]}\", (10, 60),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "                cv2.putText(frame, f\"Right Pupil - X: {right_pupil[0]}, Y: {right_pupil[1]}\", (10, 80),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "            # Loop through each face in the frame\n",
    "            for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "                # Check if the face matches any known face\n",
    "                matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "\n",
    "                # If a match is found, use the name of the known face\n",
    "                if True in matches:\n",
    "                    first_match_index = matches.index(True)\n",
    "                    name = known_face_names[first_match_index]\n",
    "\n",
    "                    # Query the database to get the game level for the current user\n",
    "                    user_data = collection.find_one({\"name\": name})\n",
    "                    if user_data:\n",
    "                        current_user_game_level = user_data.get(\"gamelevel\")\n",
    "                        print(f\"Game Level for {name}: {current_user_game_level}\")\n",
    "\n",
    "                try:\n",
    "                    # Perform emotion analysis using deepface\n",
    "                    emotions = DeepFace.analyze(frame, actions=['emotion'], enforce_detection=False)\n",
    "\n",
    "                    # Extract the dominant emotion for the first face in the list\n",
    "                    dominant_emotion = emotions[0]['dominant_emotion']\n",
    "\n",
    "                    # Print the results\n",
    "                    print(f\"Emotion: {dominant_emotion}\")\n",
    "\n",
    "                    # Update emotion counts\n",
    "                    emotion_counts[dominant_emotion] = emotion_counts.get(dominant_emotion, 0) + 1\n",
    "\n",
    "                    # Draw a rectangle around the face and display the name and emotion\n",
    "                    cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "                    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                    text = f\"Person: {name}, Emotion: {dominant_emotion}\"\n",
    "                    cv2.putText(frame, text, (left + 6, bottom - 6), font, 0.5, (255, 255, 255), 1)\n",
    "                except ValueError as e:\n",
    "                    # Handle the case where a face is not detected in the region of interest\n",
    "                    print(f\"Error: {e}\")\n",
    "\n",
    "            # Display the resulting frame\n",
    "            cv2.imshow('Video', frame)\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        # Break the loop if 'q' key is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the video capture object and close OpenCV windows\n",
    "    cap_emotion.release()\n",
    "    \n",
    "\n",
    "\n",
    "def destroy_window_if_exists(window_name):\n",
    "    try:\n",
    "        rect = cv.getWindowImageRect(window_name)\n",
    "        if rect[2] > 0 and rect[3] > 0:\n",
    "            cv.destroyWindow(window_name)\n",
    "    except cv.error:\n",
    "        pass\n",
    "\n",
    "def image_augmentation(frame, src_image, dst_points, level):\n",
    "    src_h, src_w = src_image.shape[:2]\n",
    "    frame_h, frame_w = frame.shape[:2]\n",
    "    mask = np.zeros((frame_h, frame_w), dtype=np.uint8)\n",
    "    src_points = np.array([[0, 0], [src_w, 0], [src_w, src_h], [0, src_h]])\n",
    "\n",
    "    # Destroy other level windows if a new level is opened\n",
    "    if level == 1:\n",
    "        destroy_window_if_exists(\"Level 2 Augmentation\")\n",
    "        destroy_window_if_exists(\"Admin Level Augmentation\")\n",
    "    elif level == 2:\n",
    "        destroy_window_if_exists(\"Level 1 Augmentation\")\n",
    "        destroy_window_if_exists(\"Admin Level Augmentation\")\n",
    "    elif level == \"admin\":\n",
    "        destroy_window_if_exists(\"Level 1 Augmentation\")\n",
    "        destroy_window_if_exists(\"Level 2 Augmentation\")\n",
    "\n",
    "    if level == 1:\n",
    "        # Load the background image for Level 1\n",
    "        background_image_path = \"image(1).png\"  # Change this path\n",
    "        background_image = cv.imread(background_image_path)\n",
    "\n",
    "        # Check if the image is loaded successfully\n",
    "        if background_image is None:\n",
    "            print(f\"Error: Unable to load background image from {background_image_path}\")\n",
    "            return\n",
    "\n",
    "        # Resize the background frame to match the frame dimensions\n",
    "        background_image = cv.resize(background_image, (frame_w, frame_h))\n",
    "\n",
    "        # Check if ArUco marker with ID 0 is in the bottom half and towards the middle of the frame\n",
    "        if (\n",
    "            dst_points[0][1] > frame_h // 2 and\n",
    "            dst_points[1][1] > frame_h // 2 and\n",
    "            dst_points[2][1] > frame_h // 2 and\n",
    "            dst_points[3][1] > frame_h // 2 and\n",
    "            (dst_points[0][0] + dst_points[2][0]) / 2 > frame_w // 3 and\n",
    "            (dst_points[0][0] + dst_points[2][0]) / 2 < 2 * frame_w // 3\n",
    "        ):\n",
    "            # If the condition is fulfilled, open Level 2\n",
    "            destroy_window_if_exists(\"Level 1 Augmentation\")\n",
    "            H, _ = cv.findHomography(srcPoints=src_points, dstPoints=dst_points)\n",
    "            level2 = cv.warpPerspective(src_image, H, (frame_w, frame_h))\n",
    "            cv.imshow(\"Level 2 Augmentation\", level2)\n",
    "            cv.fillConvexPoly(mask, dst_points, 255)\n",
    "            results = cv.bitwise_and(level2, level2, frame, mask=mask)\n",
    "        else:\n",
    "            # Otherwise, proceed with Level 1 as before\n",
    "            H, _ = cv.findHomography(srcPoints=src_points, dstPoints=dst_points)\n",
    "            level1 = cv.warpPerspective(src_image, H, (frame_w, frame_h))\n",
    "            # Create a mask for the marker region\n",
    "            mask_marker = np.zeros((frame_h, frame_w), dtype=np.uint8)\n",
    "            cv.fillConvexPoly(mask_marker, dst_points, 255)\n",
    "            # Create a mask for the region outside the marker\n",
    "            mask_outside_marker = cv.bitwise_not(mask_marker)\n",
    "            # Apply the mask to the background image\n",
    "            background_without_marker = cv.bitwise_and(background_image, background_image, mask=mask_outside_marker)\n",
    "            # Combine the background and the augmented image for Level 1\n",
    "            level1_with_background = cv.addWeighted(background_without_marker, 1, level1, 1, 0)\n",
    "            cv.imshow(\"Level 1 Augmentation\", level1_with_background)\n",
    "            cv.fillConvexPoly(mask, dst_points, 255)\n",
    "            results = cv.bitwise_and(level1_with_background, level1_with_background, frame, mask=mask)\n",
    "\n",
    "    elif level == 2:\n",
    "        H, _ = cv.findHomography(srcPoints=src_points, dstPoints=dst_points)\n",
    "        level2 = cv.warpPerspective(src_image, H, (frame_w, frame_h))\n",
    "        cv.imshow(\"Level 2 Augmentation\", level2)\n",
    "        cv.fillConvexPoly(mask, dst_points, 255)\n",
    "        results = cv.bitwise_and(level2, level2, frame, mask=mask)\n",
    "\n",
    "    elif level == \"admin\":\n",
    "        H, _ = cv.findHomography(srcPoints=src_points, dstPoints=dst_points)\n",
    "        admin_level = cv.warpPerspective(src_image, H, (frame_w, frame_h))\n",
    "        cv.imshow(\"Admin Level Augmentation\", admin_level)\n",
    "        cv.fillConvexPoly(mask, dst_points, 255)\n",
    "        results = cv.bitwise_and(admin_level, admin_level, frame, mask=mask)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to read images from a directory\n",
    "def read_images(dir_path):\n",
    "    img_list = []\n",
    "    files = os.listdir(dir_path)\n",
    "    for file in files:\n",
    "        img_path = os.path.join(dir_path, file)\n",
    "        image = cv2.imread(img_path)\n",
    "        img_list.append(image)\n",
    "    return img_list\n",
    "\n",
    "# Load ArUco marker dictionary and parameters\n",
    "marker_dict = aruco.Dictionary_get(aruco.DICT_4X4_50)\n",
    "param_markers = aruco.DetectorParameters_create()\n",
    "images_list = read_images(\"E:/Uni/y3/hci/phase2/IMAG_AUGMENTATION/images/augmentation\")\n",
    "\n",
    "# Start capturing video from camera index 1 for ArUco marker recognition\n",
    "cap_aruco = cv2.VideoCapture(1, cv2.CAP_DSHOW)\n",
    "\n",
    "# Create and start the processing thread for emotion detection and facial recognition\n",
    "emotion_thread = Thread(target=process_frames)\n",
    "emotion_thread.start()\n",
    "\n",
    "# Declare a variable to track the augmented state\n",
    "show_augmentation = False\n",
    "\n",
    "# Add these lines before the processing loop\n",
    "level1_counter = 0\n",
    "level1_completed = False\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap_aruco.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    gray_frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    marker_corners, marker_IDs, reject = aruco.detectMarkers(\n",
    "        gray_frame, marker_dict, parameters=param_markers\n",
    "    )\n",
    "    if marker_corners:\n",
    "        for ids, corners in zip(marker_IDs, marker_corners):\n",
    "            corners = corners.reshape(4, 2)\n",
    "            corners = corners.astype(int)\n",
    "            if ids[0] <= 5:\n",
    "                image_augmentation(frame, images_list[ids[0]], corners, level=1)\n",
    "            elif 6 <= ids[0] <= 9:\n",
    "                image_augmentation(frame, images_list[0], corners, level=2)\n",
    "            elif ids[0] == 10:\n",
    "                image_augmentation(frame, images_list[0], corners, level=\"admin\")\n",
    "                # Set the show_augmentation state to True when the admin marker is detected\n",
    "                show_augmentation = True\n",
    "\n",
    "    # Show augmented frame if the state is True\n",
    "    if show_augmentation:\n",
    "        cv.imshow(\"Augmented Frame\", frame)\n",
    "\n",
    "    cv.imshow(\"Aruco Frame\", frame)\n",
    "    key = cv.waitKey(1)\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Release the capture objects and close all windows when the processing threads finish\n",
    "emotion_thread.join()\n",
    "cap_aruco.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Calculate the dominant emotion and its percentage\n",
    "total_emotions = sum(emotion_counts.values())\n",
    "dominant_emotion, emotion_percentage = max(emotion_counts.items(), key=lambda x: x[1] / total_emotions)\n",
    "\n",
    "\n",
    "# Update the dominant emotion and its percentage in the database for the current user\n",
    "if name != \"Unknown\":\n",
    "    update_result = collection.update_one({\"name\": name}, {\"$set\": {\"emotion\": dominant_emotion, \"emotion_percentage\": emotion_percentage}})\n",
    "\n",
    "    eyegaze_data_list_json = json_util.dumps(convert_to_lists(eyegaze_data_list))\n",
    "    update_result = collection.update_one({\"name\": name}, {\"$set\": {\"eyegaze_data\": eyegaze_data_list_json}})\n",
    "    print(f\"Updated emotion and eyegaze_data for {name}: {dominant_emotion} ({emotion_percentage}%), Eyegaze Data: {eyegaze_data_list}\")\n",
    "\n",
    "else:\n",
    "    print(\"No emotions detected.\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# Inside the processing loop, after eyegaze data is accumulated\n",
    "if eyegaze_data_list:\n",
    "    create_heatmap(eyegaze_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7294cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18441e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted document ID: 65a918fe5569d49b1a7f4a90\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Replace your connection string with the actual one\n",
    "connection_string = \"mongodb+srv://reemabdelghany:reemabdelghany@cluster4.mwakgnd.mongodb.net/?retryWrites=true&w=majority\"\n",
    "\n",
    "# Create a MongoClient\n",
    "client = MongoClient(connection_string)\n",
    "\n",
    "# Access your database (replace 'your_database' with your actual database name)\n",
    "db = client.HCI\n",
    "\n",
    "# Access your collection (replace 'game_data' with your desired collection name)\n",
    "collection = db.phase2\n",
    "\n",
    "# Define the document structure with the specified fields\n",
    "document = {\n",
    "    \"id\": 1,\n",
    "    \"name\": \"Example Name\",\n",
    "    \"gamelevel\": \"Beginner\",\n",
    "    \"emotion\": \"Happy\",\n",
    "    \"eyegaze_data\": \"Your eyegaze data goes here. This field can be as big as needed.\",\n",
    "    \"date_time\": \"2024-01-18 12:00:00\"  # Replace with the actual date and time\n",
    "}\n",
    "\n",
    "# Insert the document into the collection\n",
    "result = collection.insert_one(document)\n",
    "\n",
    "# Print the inserted document's ID\n",
    "print(f\"Inserted document ID: {result.inserted_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2995fcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted document ID: 65a91e025569d49b1a7f4a94\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Replace your connection string with the actual one\n",
    "connection_string = \"mongodb+srv://reemabdelghany:reemabdelghany@cluster4.mwakgnd.mongodb.net/?retryWrites=true&w=majority\"\n",
    "\n",
    "# Create a MongoClient\n",
    "client = MongoClient(connection_string)\n",
    "\n",
    "# Access your database (replace 'your_database' with your actual database name)\n",
    "db = client.HCI\n",
    "\n",
    "# Access your collection (replace 'game_data' with your desired collection name)\n",
    "collection = db.phase2\n",
    "\n",
    "# Define the document structure with the specified fields\n",
    "document = {\n",
    "    \"id\": 1,\n",
    "    \"name\": \"yousef\",\n",
    "    \"gamelevel\": \"2\",\n",
    "    \"emotion\": \"fear\",\n",
    "    \"eyegaze_data\": \"55,33\",\n",
    "    \"date_time\": \"2024-01-18 12:00:00\"  # Replace with the actual date and time\n",
    "}\n",
    "\n",
    "# Insert the document into the collection\n",
    "result = collection.insert_one(document)\n",
    "\n",
    "# Print the inserted document's ID\n",
    "print(f\"Inserted document ID: {result.inserted_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "508f79d6-7547-4205-9fe7-5556e365231c",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:967: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12260/3463075661.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# Process the frame as desired\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'frame'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'q'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:967: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "url = 'http://192.168.100.57:8080/video'\n",
    "\n",
    "cap = cv2.VideoCapture(url)\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Process the frame as desired\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0725fad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
